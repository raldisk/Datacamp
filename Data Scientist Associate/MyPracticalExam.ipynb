{"cells":[{"cell_type":"markdown","id":"e33eda06-7d7d-445e-8cd0-60b4d4b13afb","metadata":{},"source":["# Practical Exam: House sales\n","\n","RealAgents is a real estate company that focuses on selling houses.\n","\n","RealAgents sells a variety of types of house in one metropolitan area.\n","\n","Some houses sell slowly and sometimes require lowering the price in order to find a buyer.\n","\n","In order to stay competitive, RealAgents would like to optimize the listing prices of the houses it is trying to sell.\n","\n","They want to do this by predicting the sale price of a house given its characteristics.\n","\n","If they can predict the sale price in advance, they can decrease the time to sale.\n","\n","## Data\n","\n","The dataset contains records of previous houses sold in the area.\n","\n","| Column Name   | Criteria                                                                                                                                                                                                            |\n","| ------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n","| house_id      | Nominal. </br> Unique identifier for houses. </br>Missing values not possible.                                                                                                                                      |\n","| city          | Nominal. </br>The city in which the house is located. One of 'Silvertown', 'Riverford', 'Teasdale' and 'Poppleton'. </br>Replace missing values with \"Unknown\".                                                     |\n","| sale_price    | Discrete. </br>The sale price of the house in whole dollars. Values can be any positive number greater than or equal to zero.</br>Remove missing entries.                                                           |\n","| sale_date     | Discrete. </br>The date of the last sale of the house. </br>Replace missing values with 2023-01-01.                                                                                                                 |\n","| months_listed | Continuous. </br>The number of months the house was listed on the market prior to its last sale, rounded to one decimal place. </br>Replace missing values with mean number of months listed, to one decimal place. |\n","| bedrooms      | Discrete. </br>The number of bedrooms in the house. Any positive values greater than or equal to zero. </br>Replace missing values with the mean number of bedrooms, rounded to the nearest integer.                |\n","| house_type    | Ordinal. </br>One of \"Terraced\" (two shared walls), \"Semi-detached\" (one shared wall), or \"Detached\" (no shared walls). </br>Replace missing values with the most common house type.                                |\n","| area          | Continuous. </br>The area of the house in square meters, rounded to one decimal place. </br>Replace missing values with the mean, to one decimal place.                                                             |\n"]},{"cell_type":"markdown","id":"ce597564-6bd3-4f54-830b-d5bac083c04a","metadata":{},"source":["# Task 1\n","\n","The team at RealAgents knows that the city that a property is located in makes a difference to the sale price.\n","\n","Unfortuntately they believe that this isn't always recorded in the data.\n","\n","Calculate the number of missing values of the `city`.\n","\n","-   You should use the data in the file \"house_sales.csv\".\n","\n","-   Your output should be an object `missing_city`, that contains the number of missing values in this column.\n"]},{"cell_type":"code","execution_count":1,"id":"b2cb73bf-bb81-4664-b3eb-c35f6914a652","metadata":{"executionCancelledAt":null,"executionTime":16,"lastExecutedAt":1709246661550,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import pandas as pd\n\n# Read the data\ndf = pd.read_csv(\"house_sales.csv\", na_values=[\"--\"])\n\n# Calculate the number of missing values in the 'city' column\nmissing_city = df['city'].isnull().sum()\n\n# Replace missing values in 'city' column with \"Unknown\"\ndf['city'].fillna(\"Unknown\", inplace=True)\n\n# Output the number of missing values in 'city' column\nprint(\"Number of missing values in 'city' column:\", missing_city)","outputsMetadata":{"0":{"height":37,"type":"stream"}}},"outputs":[{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'house_sales.csv'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[1;32mc:\\vscodium-files\\datascientistassociateexam.ipynb Cell 3\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/vscodium-files/datascientistassociateexam.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/vscodium-files/datascientistassociateexam.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Read the data\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/vscodium-files/datascientistassociateexam.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39mhouse_sales.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m, na_values\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39m--\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/vscodium-files/datascientistassociateexam.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Calculate the number of missing values in the 'city' column\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/vscodium-files/datascientistassociateexam.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m missing_city \u001b[39m=\u001b[39m df[\u001b[39m\"\u001b[39m\u001b[39mcity\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39misnull()\u001b[39m.\u001b[39msum()\n","File \u001b[1;32mc:\\Users\\Username\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n","File \u001b[1;32mc:\\Users\\Username\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n","File \u001b[1;32mc:\\Users\\Username\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n","File \u001b[1;32mc:\\Users\\Username\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n","File \u001b[1;32mc:\\Users\\Username\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n","\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'house_sales.csv'"]}],"source":["import pandas as pd\n","\n","df = pd.read_csv(\"house_sales.csv\", na_values=[\"--\"])\n","missing_city = df[\"city\"].isnull().sum()\n","df[\"city\"].fillna(\"Unknown\", inplace=True)\n","print(\"Number of missing values in 'city' column:\", missing_city)"]},{"cell_type":"markdown","id":"5045c039-b353-46ba-87b9-af63aaa4abf3","metadata":{},"source":["# Task 2\n","\n","Before you fit any models, you will need to make sure the data is clean.\n","\n","The table below shows what the data should look like.\n","\n","Create a cleaned version of the dataframe.\n","\n","-   You should start with the data in the file \"house_sales.csv\".\n","\n","-   Your output should be a dataframe named `clean_data`.\n","\n","-   All column names and values should match the table below.\n","\n","| Column Name   | Criteria                                                                                                                                                                                                            |\n","| ------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n","| house_id      | Nominal. </br> Unique identifier for houses. </br>Missing values not possible.                                                                                                                                      |\n","| city          | Nominal. </br>The city in which the house is located. One of 'Silvertown', 'Riverford', 'Teasdale' and 'Poppleton' </br>Replace missing values with \"Unknown\".                                                      |\n","| sale_price    | Discrete. </br>The sale price of the house in whole dollars. Values can be any positive number greater than or equal to zero.</br>Remove missing entries.                                                           |\n","| sale_date     | Discrete. </br>The date of the last sale of the house. </br>Replace missing values with 2023-01-01.                                                                                                                 |\n","| months_listed | Continuous. </br>The number of months the house was listed on the market prior to its last sale, rounded to one decimal place. </br>Replace missing values with mean number of months listed, to one decimal place. |\n","| bedrooms      | Discrete. </br>The number of bedrooms in the house. Any positive values greater than or equal to zero. </br>Replace missing values with the mean number of bedrooms, rounded to the nearest integer.                |\n","| house_type    | Ordinal. </br>One of \"Terraced\", \"Semi-detached\", or \"Detached\". </br>Replace missing values with the most common house type.                                                                                       |\n","| area          | Continuous. </br>The area of the house in square meters, rounded to one decimal place. </br>Replace missing values with the mean, to one decimal place.                                                             |\n"]},{"cell_type":"code","execution_count":null,"id":"dc9c2344-a350-461c-b5db-40768b2165a5","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1709246661602,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import pandas as pd\n\n# Read the data\ndf = pd.read_csv(\"house_sales.csv\", na_values=[\"--\"])\n\n# Check unique values in 'city' column, replace '--' with NaN\ndf['city'].replace('--', pd.NA, inplace=True)\nprint(\"Unique values in 'city' column:\", df['city'].unique())\n\n# Replace missing values in 'city' with \"Unknown\"\ndf['city'].fillna(\"Unknown\", inplace=True)\n\n# Remove missing entries in 'sale_price'\ndf = df.dropna(subset=['sale_price'])\n\n# Replace missing values in 'sale_date' with \"2023-01-01\" and convert to datetime\ndf['sale_date'] = pd.to_datetime(df['sale_date'].fillna(\"2023-01-01\"))\n\n# Replace missing values in 'months_listed' with the mean number of months listed\ndf['months_listed'].fillna(round(df['months_listed'].mean(), 1), inplace=True)\nprint(\"Unique values in 'months_listed' column:\", df['months_listed'].unique())\n\n# Replace missing values in 'bedrooms' with the mean number of bedrooms rounded to the nearest integer\ndf['bedrooms'].fillna(round(df['bedrooms'].mean()), inplace=True)\nprint(\"Unique values in 'bedrooms' column:\", df['bedrooms'].unique())\n\n# Replace abbreviations in 'house_type'\ndf['house_type'].replace({'Det.': 'Detached', 'Terr.': 'Terraced', 'Semi': 'Semi-detached'}, inplace=True)\nprint(\"Unique values in 'house_type' column:\", df['house_type'].unique())\n\n# Cleaning the 'area' column by removing non-numeric characters and converting it to float\ndf['area'] = df['area'].str.replace(' sq.m.', '').astype(float)\ndf['area'].fillna(df['area'].mean(), inplace=True)\n\n# Make sure 'area' is only float, no strings or NaN\nprint(\"Is 'area' column float:\", df['area'].dtype)\nprint(\"Missing values in 'area' column:\", df['area'].isna().sum())\n\n# Create cleaned version of the dataframe\nclean_data = df.copy()\n","outputsMetadata":{"0":{"height":297,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["Unique values in 'city' column: ['Silvertown' 'Riverford' 'Teasdale' 'Poppleton' nan]\n","Unique values in 'months_listed' column: [ 5.4  6.3  6.9  6.1  8.7  5.1  5.9  5.8  4.4  3.   4.6  3.7  6.2  5.3\n","  3.5  5.   5.5  7.8  4.9  4.7  8.9  3.8  4.8  7.6  6.4  7.9  6.6  4.1\n","  7.4  7.1  6.7  3.9  4.3  8.1  6.5  7.7  5.2  2.6  4.2  1.2  8.   5.6\n","  3.3  7.3  9.4  8.8  6.   3.6  3.2  8.5  4.5 10.4  9.2  1.7 10.2  0.8\n","  5.7  2.   2.3  8.6  7.5  9.6  9.7  6.8  2.2  2.5  4.   8.3 10.7  2.7\n","  3.4  7.   9.1  2.8  8.2 11.4 10.   2.9 10.1  7.2 10.5  9.9  3.1  9.3\n","  9.   1.3  8.4 11.   1.9 12.3  9.5  2.1  9.8  2.4  0.5 11.5  1.8  1.6\n","  1.5 10.8  1.4 11.6 10.3 10.6  0.6 11.3 11.7 11.8  1.1  1.  10.9]\n","Unique values in 'bedrooms' column: [2 5 6 4 3]\n","Unique values in 'house_type' column: ['Semi-detached' 'Detached' 'Terraced']\n","Is 'area' column float: float64\n","Missing values in 'area' column: 0\n"]}],"source":["import pandas as pd\n","\n","# Read the data\n","df = pd.read_csv(\"house_sales.csv\", na_values=[\"--\"])\n","\n","# Check unique values in 'city' column, replace '--' with NaN\n","df[\"city\"].replace(\"--\", pd.NA, inplace=True)\n","print(\"Unique values in 'city' column:\", df[\"city\"].unique())\n","\n","# Replace missing values in 'city' with \"Unknown\"\n","df[\"city\"].fillna(\"Unknown\", inplace=True)\n","\n","# Remove missing entries in 'sale_price'\n","df = df.dropna(subset=[\"sale_price\"])\n","\n","# Replace missing values in 'sale_date' with \"2023-01-01\" and convert to datetime\n","df[\"sale_date\"] = pd.to_datetime(df[\"sale_date\"].fillna(\"2023-01-01\"))\n","\n","# Replace missing values in 'months_listed' with the mean number of months listed\n","df[\"months_listed\"].fillna(round(df[\"months_listed\"].mean(), 1), inplace=True)\n","print(\"Unique values in 'months_listed' column:\", df[\"months_listed\"].unique())\n","\n","# Replace missing values in 'bedrooms' with the mean number of bedrooms rounded to the nearest integer\n","df[\"bedrooms\"].fillna(round(df[\"bedrooms\"].mean()), inplace=True)\n","print(\"Unique values in 'bedrooms' column:\", df[\"bedrooms\"].unique())\n","\n","# Replace abbreviations in 'house_type'\n","df[\"house_type\"].replace(\n","    {\"Det.\": \"Detached\", \"Terr.\": \"Terraced\", \"Semi\": \"Semi-detached\"}, inplace=True\n",")\n","print(\"Unique values in 'house_type' column:\", df[\"house_type\"].unique())\n","\n","# Cleaning the 'area' column by removing non-numeric characters and converting it to float\n","df[\"area\"] = df[\"area\"].str.replace(\" sq.m.\", \"\").astype(float)\n","df[\"area\"].fillna(df[\"area\"].mean(), inplace=True)\n","\n","# Make sure 'area' is only float, no strings or NaN\n","print(\"Is 'area' column float:\", df[\"area\"].dtype)\n","print(\"Missing values in 'area' column:\", df[\"area\"].isna().sum())\n","\n","# Create cleaned version of the dataframe\n","clean_data = df.copy()"]},{"cell_type":"markdown","id":"ff3c2889-66f3-4a6b-acac-2b12626e3244","metadata":{},"source":["# Task 3\n","\n","The team at RealAgents have told you that they have always believed that the number of bedrooms is the biggest driver of house price.\n","\n","Producing a table showing the difference in the average sale price by number of bedrooms along with the variance to investigate this question for the team.\n","\n","-   You should start with the data in the file 'house_sales.csv'.\n","\n","-   Your output should be a data frame named `price_by_rooms`.\n","\n","-   It should include the three columns `bedrooms`, `avg_price`, `var_price`.\n","\n","-   Your answers should be rounded to 1 decimal place.\n"]},{"cell_type":"code","execution_count":null,"id":"ea512a1c-e512-4f2e-8d78-323e51d01407","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1709246661650,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Use this cell to write your code for Task 3\n\n# Read the data\ndf = pd.read_csv(\"house_sales.csv\", na_values=[\"--\"])\n\n# Group data by 'bedrooms', calculate average sale price and variance\nprice_by_rooms = df.groupby('bedrooms').agg(avg_price=('sale_price', 'mean'), var_price=('sale_price', 'var')).reset_index()\n\n# Round the average sale price and variance to 1 decimal place\nprice_by_rooms['avg_price'] = price_by_rooms['avg_price'].round(1)\nprice_by_rooms['var_price'] = price_by_rooms['var_price'].round(1)\n\n# Display the table showing the difference in average sale price by number of bedrooms along with the variance\nprint(price_by_rooms)","outputsMetadata":{"0":{"height":137,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["   bedrooms  avg_price     var_price\n","0         2    67076.4  5.652896e+08\n","1         3   154665.1  2.378289e+09\n","2         4   234704.6  1.725211e+09\n","3         5   301515.9  2.484328e+09\n","4         6   375741.3  3.924432e+09\n"]}],"source":["# Use this cell to write your code for Task 3\n","\n","# Read the data\n","df = pd.read_csv(\"house_sales.csv\", na_values=[\"--\"])\n","\n","# Group data by 'bedrooms', calculate average sale price and variance\n","price_by_rooms = (\n","    df.groupby(\"bedrooms\")\n","    .agg(avg_price=(\"sale_price\", \"mean\"), var_price=(\"sale_price\", \"var\"))\n","    .reset_index()\n",")\n","\n","# Round the average sale price and variance to 1 decimal place\n","price_by_rooms[\"avg_price\"] = price_by_rooms[\"avg_price\"].round(1)\n","price_by_rooms[\"var_price\"] = price_by_rooms[\"var_price\"].round(1)\n","\n","# Display the table showing the difference in average sale price by number of bedrooms along with the variance\n","print(price_by_rooms)"]},{"cell_type":"markdown","id":"ac7038d1-7a8f-4d97-aef1-36f3f1227374","metadata":{},"source":["# Task 4\n","\n","Fit a baseline model to predict the sale price of a house.\n","\n","1.  Fit your model using the data contained in “train.csv” </br></br>\n","\n","2.  Use “validation.csv” to predict new values based on your model. You must return a dataframe named `base_result`, that includes `house_id` and `price`. The price column must be your predicted values.\n"]},{"cell_type":"code","execution_count":null,"id":"96496c59-fdd4-4683-9884-551ad93b788f","metadata":{"collapsed":false,"executionCancelledAt":null,"executionTime":52,"jupyter":{"outputs_hidden":false,"source_hidden":false},"lastExecutedAt":1709246661702,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import pandas as pd\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\n# Load training and validation data\ntrain_df = pd.read_csv(\"train.csv\")\nval_df = pd.read_csv(\"validation.csv\")\n\n# Task 2: Identify and replace missing values.\n\n# Replace missing values in 'months_listed' with the mean number of months listed\ntrain_df['months_listed'].fillna(train_df['months_listed'].mean(), inplace=True)\nval_df['months_listed'].fillna(train_df['months_listed'].mean(), inplace=True)\n\n# Define features and target variable\nfeatures = ['bedrooms', 'area', 'months_listed']\ntarget = 'sale_price'\n\n# Split the training data for model validation\nX_train, X_val, y_train, y_val = train_test_split(train_df[features], train_df[target], test_size=0.2, random_state=42)\n\n# Feature Scaling\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_val_scaled = scaler.transform(val_df[features])  # Use the same scaler as in training\n\n# Create and fit the Linear Regression model\nlinear_model = LinearRegression()\nlinear_model.fit(X_train_scaled, y_train)\n\n# Make predictions on the validation set\nlinear_predictions = linear_model.predict(X_val_scaled)\n\n# Create the result dataframe for Task 4\nbase_result = pd.DataFrame({'house_id': val_df['house_id'], 'price': linear_predictions})\n\nprint(base_result)\n","outputsMetadata":{"0":{"height":297,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["     house_id          price\n","0     1331375  118363.987119\n","1     1630115  256630.535747\n","2     1645745  381695.490685\n","3     1336775  117469.477066\n","4     1888274  255401.317124\n","..        ...            ...\n","295   1986255  343773.436812\n","296   1896276  363526.215018\n","297   1758223  238891.319798\n","298   1752010  180897.243034\n","299   1651404  350827.462628\n","\n","[300 rows x 2 columns]\n"]}],"source":["import pandas as pd\n","from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","\n","# Load training and validation data\n","train_df = pd.read_csv(\"train.csv\")\n","val_df = pd.read_csv(\"validation.csv\")\n","\n","# Task 2: Identify and replace missing values.\n","\n","# Replace missing values in 'months_listed' with the mean number of months listed\n","train_df[\"months_listed\"].fillna(train_df[\"months_listed\"].mean(), inplace=True)\n","val_df[\"months_listed\"].fillna(train_df[\"months_listed\"].mean(), inplace=True)\n","\n","# Define features and target variable\n","features = [\"bedrooms\", \"area\", \"months_listed\"]\n","target = \"sale_price\"\n","\n","# Split the training data for model validation\n","X_train, X_val, y_train, y_val = train_test_split(\n","    train_df[features], train_df[target], test_size=0.2, random_state=42\n",")\n","\n","# Feature Scaling\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_val_scaled = scaler.transform(val_df[features])  # Use the same scaler as in training\n","\n","# Create and fit the Linear Regression model\n","linear_model = LinearRegression()\n","linear_model.fit(X_train_scaled, y_train)\n","\n","# Make predictions on the validation set\n","linear_predictions = linear_model.predict(X_val_scaled)\n","\n","# Create the result dataframe for Task 4\n","base_result = pd.DataFrame(\n","    {\"house_id\": val_df[\"house_id\"], \"price\": linear_predictions}\n",")\n","\n","print(base_result)"]},{"cell_type":"markdown","id":"7c674c01-d6de-488d-b2e0-bc3bbf87def6","metadata":{},"source":["# Task 5\n","\n","Fit a comparison model to predict the sale price of a house.\n","\n","1.  Fit your model using the data contained in “train.csv” </br></br>\n","\n","2.  Use “validation.csv” to predict new values based on your model. You must return a dataframe named `compare_result`, that includes `house_id` and `price`. The price column must be your predicted values.\n"]},{"cell_type":"code","execution_count":null,"id":"538ffb3d-4008-49b6-9876-7831e025f5a4","metadata":{"executionCancelledAt":null,"executionTime":276,"lastExecutedAt":1709246661978,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import mean_squared_error\n\n# Load training and validation data\ntrain_df_comparison = pd.read_csv(\"train.csv\")\nvalidation_df_comparison = pd.read_csv(\"validation.csv\")\n\n# Preparing the data for the comparison model\nX_comparison = train_df_comparison.drop(columns=['house_id', 'sale_price', 'sale_date'])\ny_comparison = train_df_comparison['sale_price']\n\n# Identifying categorical columns in the new dataset for the comparison model\ncategorical_cols_comparison = [col for col in X_comparison.columns if X_comparison[col].dtype == 'object']\n\n# Creating a transformer for preprocessing in the new dataset for the comparison model\npreprocessor_comparison = ColumnTransformer(\n    transformers=[\n        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols_comparison),\n    ],\n    remainder='passthrough'  # keeping other columns untouched\n)\n\n# Creating a pipeline with preprocessing and the Random Forest Regressor for the comparison model\nmodel_comparison = Pipeline(steps=[\n    ('preprocessor', preprocessor_comparison),\n    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))\n])\n\n# Fitting the model with the new dataset for the comparison model\nmodel_comparison.fit(X_comparison, y_comparison)\n\nprint(\"Comparison model (Random Forest Regressor) trained successfully.\")\n\n# Preparing the validation data (similar to the training data preparation for the comparison model)\nX_validation_comparison = validation_df_comparison.drop(columns=['house_id', 'sale_date'])\n\n# Making predictions using the trained comparison model\nvalidation_df_comparison['price'] = model_comparison.predict(X_validation_comparison)\n\n# Creating the compare_result DataFrame with house_id and predicted price\ncompare_result = validation_df_comparison[['house_id', 'price']]\n\n# Displaying the first few rows of the compare_result DataFrame\nprint(compare_result.head())\n","outputsMetadata":{"0":{"height":157,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["Comparison model (Random Forest Regressor) trained successfully.\n","   house_id      price\n","0   1331375   82582.62\n","1   1630115  303256.87\n","2   1645745  404809.08\n","3   1336775  106624.68\n","4   1888274  267768.22\n"]}],"source":["import pandas as pd\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.pipeline import Pipeline\n","from sklearn.model_selection import train_test_split, cross_val_score\n","from sklearn.metrics import mean_squared_error\n","\n","# Load training and validation data\n","train_df_comparison = pd.read_csv(\"train.csv\")\n","validation_df_comparison = pd.read_csv(\"validation.csv\")\n","\n","# Preparing the data for the comparison model\n","X_comparison = train_df_comparison.drop(columns=[\"house_id\", \"sale_price\", \"sale_date\"])\n","y_comparison = train_df_comparison[\"sale_price\"]\n","\n","# Identifying categorical columns in the new dataset for the comparison model\n","categorical_cols_comparison = [\n","    col for col in X_comparison.columns if X_comparison[col].dtype == \"object\"\n","]\n","\n","# Creating a transformer for preprocessing in the new dataset for the comparison model\n","preprocessor_comparison = ColumnTransformer(\n","    transformers=[\n","        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_cols_comparison)\n","    ],\n","    remainder=\"passthrough\",  # keeping other columns untouched\n",")\n","\n","# Creating a pipeline with preprocessing and the Random Forest Regressor for the comparison model\n","model_comparison = Pipeline(\n","    steps=[\n","        (\"preprocessor\", preprocessor_comparison),\n","        (\"regressor\", RandomForestRegressor(n_estimators=100, random_state=42)),\n","    ]\n",")\n","\n","# Fitting the model with the new dataset for the comparison model\n","model_comparison.fit(X_comparison, y_comparison)\n","\n","print(\"Comparison model (Random Forest Regressor) trained successfully.\")\n","\n","# Preparing the validation data (similar to the training data preparation for the comparison model)\n","X_validation_comparison = validation_df_comparison.drop(\n","    columns=[\"house_id\", \"sale_date\"]\n",")\n","\n","# Making predictions using the trained comparison model\n","validation_df_comparison[\"price\"] = model_comparison.predict(X_validation_comparison)\n","\n","# Creating the compare_result DataFrame with house_id and predicted price\n","compare_result = validation_df_comparison[[\"house_id\", \"price\"]]\n","\n","# Displaying the first few rows of the compare_result DataFrame\n","print(compare_result.head())"]}],"metadata":{"editor":"DataCamp Workspace","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":5}
